{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edd66edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93244b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_to_file(text):\n",
    "    with open(\"outputs_optimized_1.txt\", \"a\") as file:\n",
    "        # Write content to the file\n",
    "        file.write(f\"{text}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf033a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     new_label1  new_label2  new_label3  new_label4  new_label5  new_label6  \\\n",
      "0     -7.838596    9.534278    4.172194   -3.346301  -13.316606    0.400746   \n",
      "1     -2.223975   11.901087   -4.437231   -0.161246    5.624779    2.318205   \n",
      "2     23.682496    4.600548   -4.317800   -0.566981    0.394200   -1.286066   \n",
      "3     -3.591944   -0.503726    6.786496    1.484504   12.799750    0.384067   \n",
      "4     -8.145573   10.144122  -15.049888    0.777420    1.684849   -0.069158   \n",
      "..          ...         ...         ...         ...         ...         ...   \n",
      "745    1.324223   -3.381910    1.394137   -0.378533   11.315143   -4.021726   \n",
      "746    0.345660   -9.777600   -2.471034  -10.607004   -3.272883   -3.499299   \n",
      "747   -0.719725   -5.764254    3.409072    4.193678   13.907744   -1.106457   \n",
      "748   15.285476   -0.509129    4.176289   -1.693783    6.100749    3.516521   \n",
      "749   -4.446979    5.020536    2.645054   -5.967075   -9.168903    0.632402   \n",
      "\n",
      "     new_label7  new_label8  new_label9  new_label10  ...  new_label300  \\\n",
      "0      5.511396   -8.562852    0.846186    -6.437468  ...     -0.215341   \n",
      "1     -3.977538    7.918467   -6.440164    -2.712613  ...     -0.122656   \n",
      "2     -1.435298   -2.376424   -3.565152    -1.922440  ...     -0.205790   \n",
      "3     -3.065977   -0.266637   10.112177    -4.897300  ...     -0.240042   \n",
      "4      5.516973   -3.701267    1.546035     1.093777  ...      0.113358   \n",
      "..          ...         ...         ...          ...  ...           ...   \n",
      "745   -3.330887   -4.549970    7.363402    -3.304608  ...     -0.295905   \n",
      "746   -0.598764    4.602106    1.821347    -0.725115  ...     -0.320224   \n",
      "747   -2.696103   -5.659726   11.043592     0.692945  ...     -0.703269   \n",
      "748    0.215750   -4.203160   -6.125191    -6.063615  ...      0.135444   \n",
      "749    3.221061   -5.047560    1.712032    -2.325128  ...      0.635135   \n",
      "\n",
      "     new_label301  new_label302  new_label303  new_label304  new_label305  \\\n",
      "0        0.138331     -0.196763     -0.495820      0.206941     -0.449331   \n",
      "1       -0.044958      0.355948     -0.831503     -0.298372     -0.354664   \n",
      "2        0.462997      0.624657     -0.223711      0.085223     -0.144675   \n",
      "3        1.190590      0.138941      0.748747      0.239333     -0.659481   \n",
      "4       -0.004135     -0.144699      0.274592     -0.114744      0.619157   \n",
      "..            ...           ...           ...           ...           ...   \n",
      "745     -0.848107      0.191270      0.355634      0.136036     -0.384097   \n",
      "746     -0.210616     -0.496404     -0.305092     -0.366697     -0.210349   \n",
      "747     -0.102150     -0.905462      0.271325      0.437756     -0.386657   \n",
      "748     -0.217696     -0.966574      0.591859      0.018526     -0.191340   \n",
      "749     -0.013573     -0.470591     -0.863606      1.038530      0.826091   \n",
      "\n",
      "     new_label306  new_label307  new_label308  new_label309  \n",
      "0        0.707231      0.135123      0.484519     -0.092654  \n",
      "1        0.202768      0.928755     -0.434610      0.337189  \n",
      "2       -0.225275     -0.155328     -0.145560      0.373476  \n",
      "3       -0.822981     -0.181275     -0.597404      0.364718  \n",
      "4       -0.442240     -0.179003      0.029544      0.090803  \n",
      "..            ...           ...           ...           ...  \n",
      "745     -0.132778     -0.081151      0.051532      0.678595  \n",
      "746      0.102841     -0.330591     -0.217841      0.604331  \n",
      "747     -0.482736     -0.566750     -0.151320      0.977074  \n",
      "748      0.399458      0.377174     -0.700528      0.030448  \n",
      "749     -0.784106      0.043912      0.108240     -0.073777  \n",
      "\n",
      "[29850 rows x 309 columns]\n",
      "0      45\n",
      "1      45\n",
      "2      45\n",
      "3      45\n",
      "4      45\n",
      "       ..\n",
      "745    39\n",
      "746    39\n",
      "747    39\n",
      "748    39\n",
      "749    39\n",
      "Name: label_1, Length: 29850, dtype: int64\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "all_labels = [\"label_1\",\"label_2\",\"label_3\", \"label_4\"]\n",
    "for label in all_labels:\n",
    "    droping_labels = all_labels.copy()\n",
    "    droping_labels.remove(label)\n",
    "\n",
    "    train = pd.read_csv(\"./train.csv\")\n",
    "    valid = pd.read_csv(\"./valid.csv\")\n",
    "\n",
    "    train.drop(droping_labels, axis=1, inplace=True)\n",
    "    valid.drop(droping_labels, axis=1, inplace=True)\n",
    "\n",
    "    if(len(train.columns[train.isnull().any()])>0):\n",
    "        print(f\"{label} has missing values in train set\")\n",
    "        train.dropna(inplace=True)\n",
    "\n",
    "    if(len(valid.columns[train.isnull().any()])>0):\n",
    "        print(f\"{label} has missing values in valid set\")\n",
    "        valid.dropna(inplace=True)\n",
    "\n",
    "    # splitting features and the label\n",
    "    x_train = train.drop([label], axis=1)\n",
    "    y_train = train[label]\n",
    "    x_valid = valid.drop([label], axis=1)\n",
    "    y_valid = valid[label]\n",
    "    \n",
    "    smote = SMOTE(sampling_strategy='auto', random_state=42)  # You can adjust the sampling strategy\n",
    "\n",
    "    # Fit and transform the dataset\n",
    "    rx_train, ry_train = smote.fit_resample(x_train, y_train)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # fit the scaler\n",
    "    sx_train = pd.DataFrame(scaler.fit_transform(rx_train), columns=rx_train.columns)\n",
    "    sx_valid = pd.DataFrame(scaler.transform(x_valid), columns=x_valid.columns)\n",
    "    \n",
    "    for n_comp in [0.95, 0.96, 0.98, 0.99, None]:\n",
    "        \n",
    "        if n_comp is not None:\n",
    "            pca = PCA(n_components= n_comp)\n",
    "\n",
    "            psx_train = pca.fit_transform(sx_train)\n",
    "            psx_valid = pca.transform(sx_valid)\n",
    "            \n",
    "            new_len = len(psx_train[0])\n",
    "            \n",
    "            psx_train = pd.DataFrame(psx_train, columns=[f\"new_label{i}\" for i in range(1, len(psx_train[0])+1)])\n",
    "            psx_valid = pd.DataFrame(psx_valid, columns=[f\"new_label{i}\" for i in range(1, len(psx_valid[0])+1)])\n",
    "        else:\n",
    "            psx_train = sx_train\n",
    "            psx_valid = sx_valid\n",
    "\n",
    "        # Create an instance of MyModel\n",
    "#         init_model = SVC()\n",
    "\n",
    "#         # Fit the model to the training data\n",
    "#         init_model.fit(x_train, y_train)\n",
    "\n",
    "#         # Make predictions on the test data\n",
    "#         y_pred = init_model.predict(x_valid)\n",
    "\n",
    "#         # Print the accuracy of the model\n",
    "#         accuracy = (y_pred == y_valid).mean()\n",
    "#         print(f\"Accuracy for {label} with n_comp {n_comp}: {accuracy}\")\n",
    "#         append_to_file(f\"Initial accuracy for {label} with n_comp {n_comp}: {accuracy}\")\n",
    "\n",
    "        # Example of using RandomizedSearchCV to tune hyperparameters\n",
    "        param_dist = {\n",
    "            'C': uniform(0.1, 100.0),\n",
    "            'kernel': ['linear', 'rbf', 'poly'],\n",
    "            'gamma': uniform(0.001, 0.1)\n",
    "        }\n",
    "        \n",
    "        svc = SVC()\n",
    "\n",
    "        random_search = RandomizedSearchCV(\n",
    "            estimator=svc,\n",
    "            param_distributions=param_dist,\n",
    "            n_iter=20,  # Number of random combinations to try\n",
    "            cv=5,  # Number of cross-validation folds\n",
    "            verbose=2,\n",
    "            random_state=42,  # Set a random seed for reproducibility\n",
    "            n_jobs=-1  # Use all available CPU cores for parallel computation\n",
    "        )\n",
    "        \n",
    "        full_x = pd.concat([psx_train,psx_valid], axis = 0)\n",
    "        full_y = pd.concat([ry_train, y_valid], axis = 0)\n",
    "        \n",
    "        random_search.fit(full_x, full_y)\n",
    "\n",
    "        print(f\"Best hyperparameters found by RandomizedSearchCV for label {label} with n_comp {n_comp}:\")\n",
    "        print(random_search.best_params_)\n",
    "        append_to_file(f\"Best params for {label} with n_comp {n_comp}: {random_search.best_params_}\")\n",
    "\n",
    "        print(f\"Best Score: for label {label} with n_comp {n_comp}\", random_search.best_score_)\n",
    "        append_to_file(f\"Best score for {label} with n_comp {n_comp}: {random_search.best_score_}\")\n",
    "\n",
    "        # Perform cross-validation to evaluate the model with the best hyperparameters\n",
    "    #     cross_val_scores = cross_val_score(random_search, X, y, cv=5, n_jobs=-1)\n",
    "\n",
    "        # Print cross-validation scores\n",
    "    #     print(\"Cross-Validation Scores:\", cross_val_scores)\n",
    "    #     append_to_file(f\"Cross-Validation Scores for {label} : {cross_val_scores} \\n\")\n",
    "    #     print(\"Mean CV Score:\", np.mean(cross_val_scores))\n",
    "    #     append_to_file(f\"Mean CV Score for {label} : {np.mean(cross_val_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891991fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
